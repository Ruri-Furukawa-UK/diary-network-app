import streamlit as st
from nlp_utils import extract_topics
from graph_utils import create_network
from db import init_db, add_entry, load_entries, delete_entry

# åˆæœŸåŒ–
init_db()

st.title("ğŸ“ æ—¥è¨˜ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ—ãƒªï¼ˆDBç‰ˆï¼‰")

# æ—¥è¨˜æŠ•ç¨¿ãƒ•ã‚©ãƒ¼ãƒ 
with st.form(key='diary_form'):
    diary_text = st.text_area("ä»Šæ—¥ã®æ—¥è¨˜ã‚’æ›¸ã„ã¦ãã ã•ã„")
    submit = st.form_submit_button("æŠ•ç¨¿")
    if submit and diary_text.strip():
        topics = extract_topics(diary_text)
        add_entry(diary_text, topics)
        st.success(f"æ—¥è¨˜ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ ãƒˆãƒ”ãƒƒã‚¯: {topics}")

# æŠ•ç¨¿æ¸ˆã¿æ—¥è¨˜ã®ä¸€è¦§
diary_data = load_entries()
if diary_data:
    st.subheader("æŠ•ç¨¿æ¸ˆã¿æ—¥è¨˜ä¸€è¦§")
    for id_, date, text, topics in diary_data:
        st.markdown(f"**{date}**: {text}")
        st.caption(f"ãƒˆãƒ”ãƒƒã‚¯: {topics}")

        # å‰Šé™¤ãƒœã‚¿ãƒ³
        button_key = f"delete_{id_}"
        
        if st.button("å‰Šé™¤", key=button_key):
            delete_entry(id_)
            st.success("å‰Šé™¤ã—ã¾ã—ãŸã€‚ãƒšãƒ¼ã‚¸ã‚’å†èª­ã¿è¾¼ã¿ã™ã‚‹ã¨åæ˜ ã•ã‚Œã¾ã™ã€‚")


# ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å¯è¦–åŒ–
if len(diary_data) >= 2:
    st.subheader("æ—¥è¨˜ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")
    data_for_network = [{"text": d[2], "topics": d[3].split(", ")} for d in diary_data]
    net = create_network(data_for_network)
    net.save_graph("network.html")
    with open("network.html", "r", encoding="utf-8") as f:
        html_content = f.read()
    st.components.v1.html(html_content, height=500)

