# app/main.py
import streamlit as st
import sqlite3
from nlp_utils import extract_topics
from graph_utils import create_network

# --- DBåˆæœŸåŒ– ---
def init_db():
    conn = sqlite3.connect("diary.db")
    c = conn.cursor()
    c.execute('''
        CREATE TABLE IF NOT EXISTS diary (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            text TEXT,
            topics TEXT
        )
    ''')
    conn.commit()
    conn.close()

def save_to_db(text, topics):
    conn = sqlite3.connect("diary.db")
    c = conn.cursor()
    c.execute("INSERT INTO diary (text, topics) VALUES (?, ?)", (text, ", ".join(topics)))
    conn.commit()
    conn.close()

def load_from_db():
    conn = sqlite3.connect("diary.db")
    c = conn.cursor()
    c.execute("SELECT id, text, topics FROM diary")
    data = c.fetchall()
    conn.close()
    return data

# --- åˆæœŸè¨­å®š ---
init_db()
st.title("ğŸ“ æ—¥è¨˜ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ãƒ—ãƒªï¼ˆDBä¿å­˜ç‰ˆï¼‰")

# ğŸ“Œ æ—¥è¨˜æŠ•ç¨¿
with st.form(key='diary_form'):
    diary_text = st.text_area("ä»Šæ—¥ã®æ—¥è¨˜ã‚’æ›¸ã„ã¦ãã ã•ã„")
    submit = st.form_submit_button("æŠ•ç¨¿")

    if submit and diary_text.strip():
        topics = extract_topics(diary_text)
        save_to_db(diary_text, topics)
        st.success(f"æ—¥è¨˜ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼ ãƒˆãƒ”ãƒƒã‚¯: {topics}")

# ğŸ“œ æŠ•ç¨¿æ¸ˆã¿æ—¥è¨˜ã®ä¸€è¦§è¡¨ç¤º
diary_data = load_from_db()
if diary_data:
    st.subheader("æŠ•ç¨¿æ¸ˆã¿æ—¥è¨˜ä¸€è¦§")
    for id_, text, topics in diary_data:
        st.markdown(f"**æ—¥è¨˜{id_}**: {text}")
        st.caption(f"ãƒˆãƒ”ãƒƒã‚¯: {topics}")

    # ğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¡¨ç¤º
    if len(diary_data) >= 2:
        st.subheader("æ—¥è¨˜ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯")
        data_for_network = [{"text": d[1], "topics": d[2].split(", ")} for d in diary_data]
        net = create_network(data_for_network)
        net.save_graph("network.html")
        with open("network.html", "r", encoding="utf-8") as f:
            html_content = f.read()
        st.components.v1.html(html_content, height=500)

